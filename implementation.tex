%!TEX root = main.tex


\section{Implementation and Usage}

With explicit managed state and consistent snapshotting at its core, Flink maintains a rich ecosystem of backends, connectors and other services that interplay seamlessly and benefit from the capabilities of its global state establishment mechanism. In this section, we summarize how each of these subsystems builds on-top of Flink's core architecture, while expanding it with asynchronous communication, delivery guarantees and external state querying support.

\label{sec:implementation}

\subsection{State Backend Support}

Managed state consistency is coordinated by Flink's snapshotting algorithm (\autoref{sec:snapshots}), however, state access and persistence are the main concerns of the state backend module. There are currently three different backends supported by the Flink stack : 1) \emph{In-Memory}, 2) \emph{File-Based} and 3) \emph{Out-of-Core}. Depending on the overall expected managed state accumulated in a pipeline, each of the backends offers a suitable trade-off between throughput and scalability.

\para{In-Memory}
The \emph{In-Memory} backend maintains active managed state in local, allocated heap space and snapshotted state within the Job Manager's heap space. This is, in some distinct use-cases, a preferable choice that yields very high throughput. For example, pipeline testing and debugging or actual deployments with low state capacity requirements such as filtering and basic ETL can make a reasonable use of this backend. Upon each task's \texttt{triggerSnapshot()} invocation local state is serialized, copied and transfered to the Job Manager together with typical snapshot metadata. As a result, the Job Manager needs to have enough heap space allocated in order to be able sustain all physical task materialized states for each snapshot.

\para{File-Based:}
Most often, complete snapshots involve more aggregated state than the allocated memory of a single node. The \emph{File-Based} backend only deviates from \emph{In-memory} when it comes to snapshotting. Once a snapshot is invoked the state is being copied to a configured distributed file system directory (e.g., HDFS). As a result, snapshot metadata is also kept to a minimum, while throughput can remain high since operations on uncommitted memory happen in-place at the local heap.

\para{Out-of-Core:}
Complex pipelines often need to maintain very large managed state such as long sliding windows. In such cases, local heap space is insufficient to sustain even locally accessed active state, especially for certain task operators (e.g., Flink's \texttt{WindowOperator}). Flink provides an \emph{out-of-core} backend that decouples state operations performed on each task from the physical location where state itself is persisted and updated. In its current implementation, out-of-core state is interfaced with an embedded file-backed key-value database (i.e., RocksDB). Therefore, state capacity is only limited by the file system space allocated at the host where this backend is deployed. Moreover, operations triggered on managed state such as \texttt{update} and \texttt{add} are carried over to the embedded key-value store instead. One of the key benefits, enabled out-of-the-box with such a scheme is that most per-key operations can be executed asynchronously at the backend without sacrificing throughput. However, the main trade-off of accessing state off-heap is the extensive serialization operations on each state \texttt{read} or \texttt{update} which can lead to lower throughput compared to heap-based active state. Nevertheless, this can be amortized, having less overhead during  garbage collection, flexible data locality, and copy-on-write support. In fact, an alternative version of the in-memory backend that operates on serialized data is currently considered to exploit the same benefits.

%\stefan{One big difference to the in-memory backends, and also a big source% of performance loss, is that this backend has to use serialization on each state read or update! Apart from this backend, keeping data serialized also has some advantages over objects on the heap: less overhead for the garbage collector, potentially higher data locality, and easier supoort for copy-on-write. This is why we are also planning to have an in-memory backend that works on serialized data.}. On the other hand, state value retrievals can take more time to complete, especially if some specific state has to be retrieved from compacted files on disk and it is no longer within the backend's memory.

\subsection{Asynchronous Snapshots and Notifications}
\label{sec:async}
One of the advantages of the pipelined snapshotting protocol presented in \autoref{sec:snapshots} is that it does not restrain the actual acquisition of snapshots to be synchronous. A call of \texttt{triggerSnapshot()} by each task is expected to create an identical copy of the current state of that task. In case there is support by a backend module to execute this operation asynchronously, it can be used without violating consistency. The \emph{out-of-core} backend of Flink offers the capability to trigger snapshots in a purely asynchronous way by copying the full compacted key-value database to a backup directory by another thread, thus, letting normal processing proceed without interruptions. 
%\stefan{Right now I am also working on an asynchronous in-memory state backend. For the future we are planning to also allow for incremental snapshots of the RocksDB backend. If you want more information about this, let me know.} 
Once local snapshotting operations have been completed the notifications are triggered back at the tasks and carried out to the \emph{JobManager} alongside associated meta-data where a full snapshot can be declared as complete. Asynchronous snapshotting also unlocks the possibility to multiplex multiple instances of the protocol running at the same time in a dataflow graph. That means that while for example a periodic snapshot is undergoing, a user can also trigger a savepoint and both of the associated snapshots will run concurrently and distributively, each invoking its own asynchronous state copy and epoch.

Another feature that is provided to tasks as an optional asynchronous subscription-based mechanism is to trigger notifications about completed snapshots back at the tasks that request them. This is especially useful for garbage collection, discarding write ahead logs or for executing output commit protocols as we explain further in \autoref{sec:outputcommit}.

\subsection{Queryable State}

A recent, yet notable addition among Flink's state management mechanisms, is the ability to execute selective ad-hoc queries on managed state from outside the system. Continuous data stream processing pipelines often build and maintain partitioned state inside operators that could be potentially harnessed at any time and used to provide fast, actionable knowledge, in a similar fashion to in-memory database usage \cite{kipfanalytics}. Queryable state allows for any declared managed state within a pipeline, currently scoped by key, to be accessed outside the system for asynchronous reading, through a subscription-based API. First, managed state that allows for query access is declared in the original application. Upon state declaration, introduced in \autoref{sec:managedstate}, it is possible to allow access from external queries by simply setting a flag in the descriptor that is used to create the actual state, having an assigned unique name for this specific state to be accessed, as such:

\begin{lstlisting}[language=scala]
//stream processing application logic
val descriptor: ValueStateDescriptor[MySchema] = ...
descriptor.setQueryable("myKV")
...
val mutState: ValueState[MySchema] = ctx.getState(descriptor)
\end{lstlisting}

\para{} Upon deployment, a state registry service gets initiated and runs concurrently with the task that holds write access to that state. A client that wishes to read the state for a specific key can, at any time submit an asynchronous query (obtaining a \texttt{future}) to that service, specifying the job id, registered state name and key, as shown below:

\begin{lstlisting}[language=scala]
//client logic
val client = QueryableStateClient(cfg);
var readState: Future[_] = client.getKVState(job, "myKV", key);
\end{lstlisting}
%MyDeserializer[MySchema](Await.result(readState, timeout));
The current implementation of queryable state allows for retrieving and sending, internally through Akka messaging, copies of serialized state values straight from the operator heap memory or the backend store in case of out-of-core state. Despite current limitations to point lookups of the current value (\texttt{ListState} is not yet supported as of Flink v1.2.0) the ability to access state generalizes the usages of a stream processor, beyond the needs of data transformation or application logic needs and adds further potential for ad-hoc data analysis. From a traditional database isolation-level viewpoint, this feature also includes the ability to access and operator on uncommitted state, thus, allowing for a more relaxed, yet highly accessible \emph{read-uncommitted} read isolation, compared to already provided \emph{read-committed} read isolation guaranteed by its specialized sinks through its snapshotting mechanism (see \autoref{sec:outputcommit}). \gyula{maybe mention the potential of also offering read-committed queryable in case that is supported and well integrated with the backend.}

\subsection{Output Commit}
\label{sec:outputcommit}

So far we have considered consistency guarantees associated with the internal state of the system. However, it is most often important to offer guarantees regarding the side effects that a pipeline leaves to the outside world, whether that is a distributed database, file system or message queue. A pipeline interfaces with the outside world mainly via its dataflow sinks. Thus, it is often crucial that sinks can offer exactly-once delivery guarantees. The feasibility of achieving ``read-committed'' isolation guarantees to external writes depends on the properties of the system upon which sinks commit output and typically comes at a higher latency cost that can, at-times, violate strong SLAs on latency. A pipeline can always be halted between snapshots after a failure or an urgent reconfiguration request and both input and state can be rolled back consistently, as it was described in \ref{sec:core}. However, the same cannot always be guaranteed about the output. If sinks are connected, for example, to a printer that instantly flushes data on paper, a rollback would possibly print the same or alternating text twice. Flink's programming model is equipped with two main types of sinks that facilitate ``read-committed'' output and build on the snapshotting mechanism: the 1) Idempotent Database Sink and 2) Bucketing File Sink.

\para{Idempotent Database Sink: } Idempotency is a property used extensively by several systems at the presence of failures in order to encourage repeatability and alleviate bookkeeping efforts and complex decision protocols to offer delivery guarantees\cite{CUSTOM:web/SparkStructuredStreaming,millwheel}. Flink's database sink executes user-defined, idempotent database queries to a distributed database for each input received per parallel sink. Deterministic streams (that do not involve stream interleaving or other forms of non-determinism) can rely on that sink to operate consistently with the database. However, in most cases where deterministic processing cannot be guaranteed, a write-ahead log of prepared query statements is kept as part of the state of that sink and maintained per-epoch. Once an asynchronous notification (\autoref{sec:async}) arrives regarding a completed epoch snapshot, the database sink commits all pending writes to the database at the expense of additional output latency (for a snapshot to complete and its notification to arrive to the sinks). Query idempotency guarantees that even failures during committing can be resolved by simply re-committing the same queries and thus, eventually, leaving the same side effects upon subsequent system reconfigurations. 
%\paris{what are the database properties required and why is it only cassandra based?}

\begin{figure}[t!]
\centering
\includegraphics[width=\textwidth / 2]{figures/filecommit.pdf}
\caption{A visualization of Bucketing File Sinks.} 
\label{fig:filecommit}
\vspace{-4mm}
\end{figure}

\para{Bucketing File Sink: } Committing state to a distributed file systems (e.g. HDFS) has to be made in a coordinated way since a file has to be consistent across all its file partitions. Flink's bucketing file sink (depicted in \autoref{fig:filecommit}) eliminates the need for a write-ahead log and eagerly appends stream output within uncommitted distributed file directories which group (or ``bucket'') partition parts by time-period. After a pre-configured inactivity time-period \texttt{in-progress} directories become \texttt{pending} and are ready to be committed. The Bucketing File Sink integrates with Flink's snapshotting algorithm and associates epochs with buckets. Once a file bucket is under \texttt{pending} mode and an asynchronous notification for an associated epoch has been received, it can be moved to a \texttt{committed} state via a \texttt{rename} operation. Potential disruptions between epochs resolve into a \texttt{truncate} (Posix) operation, which is currently supported by major distributed file systems and conveniently reverses append operations. \paris{i guess the non-truncate approach is ugly. Should we write about it?}

\subsection{Asynchronous IO}
\paris{What I write here does not seem to be the actual implementation. The implementation does event sourcing which is a bit sucky tbh...}
Most often, all logic within a pipeline is executed within its stateful tasks and data ingestion from external systems flows directly through pipeline sources. Flink enforces this restriction in order to guarantee consistent, managed state and more importantly to avoid \emph{blocking} operations that can create a bottleneck or even a deadlock in a pipeline. If the application logic deems access to external systems necessary, Flink offers an Asynchronous I/O model for such operations. 

Special \texttt{AsyncIO} operators in Flink, provide the necessary callbacks for invoking and handling asynchronous, user-defined requests to external systems (e.g., a database). Asynchronous requests are internally logged and maintained as part of the managed state of \texttt{AsyncIO} operators. Responses are also logged in-advance as part of the state and their handling can be optionally pre-configured to be FIFO according to their invocation or event time order (based on low watermarks \cite{millwheel,akidau2015dataflow,li2008out}). Asynchronous operations integrate seamlessly with the core snapshotting algorithm since both invocation and handling logic is executed within the same regular processing thread of the encapsulating task, thus, yielding atomic and controlled access to managed state. In case of rollback recovery, all logged requests are being repeated and pending results are eventually processed within their respective epoch in the pre-defined order. There are no guarantees, whatsoever, regarding the side effects of potential async write operations that will be repeated in case or rollback recovery on external systems. Similarly to Google's Millwheel \cite{millwheel},  all async I/O operations that communicate with external systems should be idempotent to satisfy strong consistency guarantees on those systems.

\subsection{High Availability \& Reconfiguration}

All metadata associated with the active state of long-running pipelines is kept within the \texttt{JobManager} node. This makes the importance of this central node quite important for the general functionality of the system and evidently it is indeed a single-point-of-failure. A \texttt{JobManager} failure would halt the coordination of the snapshotting protocol, the collection and management of snapshot metadata as well as making further job deployments and rescaling requests unavailable, thus, eliminating the purpose of any fault tolerance mechanism. To deal with such a critical failure we employ a passive-standby high availability scheme where configured standby nodes can take undertake the coordination role of the failed master node via distributed leader election. When this mode is enabled, the coordination of vital decisions such as job deployment and scheduling are undertaken via a distributed decision protocol which logs committed operations atomically (currently utilizing a \texttt{Zookeeper} quorum executing the \texttt{zab} protocol \cite{hunt2010zookeeper}). This introduces some additional latency for such critical operations, however, non critical decisions such as the persistence of the most recent snapshot metadata for a job, are asynchronously committed and logged. The worst scenario of a potential failure during non-critical commits would simply result into, a yet valid restoration of active pipeline state from snapshots that correspond to earlier epochs that have been committed prior to the failure.

	