%!TEX root = main.tex

\section{Introduction}
\label{sec:intro}

%- What is the problem?
Data stream processing has been traditionally decoupled from database management systems. When it comes to continuous data processing, stream processors, have been viewed as a secondary tool for generating approximate, often inconsistent results in a timely manner. Recent advances in data streaming technologies have focused on providing distributed programming model semantics \cite{CUSTOM:web/Storm,CUSTOM:web/Samza} that can address ever-increasing data volumes. While this enables a new variety of applications, challenges related to consistent state management remain a concern of the user and are typically lifted to external database management systems (e.g. Lambda Architecture \cite{marz2015big}).

Developers that architect critical continuous applications such as financial data processing, IoT systems, and user-facing live services face a set of hard challenges. First, the lack of explicit computational state abstractions in such systems forces them to declare and maintain state externally, decoupled from computational logic. Thus, the responsibility of ensuring data consistency must lie in the application logic, coordinating computation with external database systems. In most cases, this is very complex and error-prone. Furthermore, the transactional performance of the external storage layer can become the bottleneck of the whole application. On-top of consistency needs, operational challenges arise in a real-world environment when there is need to scale in or out, deal with partial failures or to simply change application logic with software patches, in a transparent manner. While several of these important state management issues have been previously researched and applied in production systems, most known approaches fall short of doing so. For example, micro-batching techniques for reliable continuous processing (e.g. Apache Spark \cite{zaharia2012discretized,CUSTOM:web/trident}) sacrifice programming model transparency and processing latency by enforcing batch-centric application logic. Other proprietary continuous processing system solutions \cite{millwheel} on the other hand, build on heavy transactional per-record processing. This pushes critical complexities outside the system relying on high-performance key-value stores, special hardware and optimized network infrastructure. 

Apache Flink \cite{CUSTOM:web/Flink} is a stream processing system that addresses these challenges by integrating state management with computational logic. Flink's dataflow execution runtime layer encapsulates distributed, record-centric operator logic to express complex data pipelines. Consistent application state is a first-class citizen in data processing pipelines written in Flink and is persisted by a modular state backend. Furthermore, the system manages operations on state and orchestrates failure recovery and reconfiguration whenever necessary without imposing heavy impact on the execution or violating consistency. Pipeline output committed to a database, distributed file system, or other systems respects standard isolation level guarantees that have been traditionally supported by transactional databases such as ``read-committed'' or ``read-uncommitted'' application state. 

The core of our approach in Apache Flink builds on \emph{distributed snapshots}, a  classical concept that is proliferating anew today. Distributed snapshots enable rollback recovery of arbitrary distributed processes \cite{elnozahy2002survey} to a prior globally consistent execution state. Several distributed computing systems have used different variations of snapshotting mechanisms \cite{murray2013naiad,low2012distributed}, though adopting sub-optimal protocols that impose global synchrony and thus halt computational progress while also persisting more state than needed within snapshots (i.e. records within network buffers).

%\stephan{Two comments on the last sentence: (1) State is not necessary "local", but may very well be remote. I think what you mean here is state that looks as if it is local and is used similar to operator-local state. Flink actually does not make the assumption that state is local (see Gyula's MySQL state backend) and the new DataFlow runner (as a service on Google Cloud) for Beam uses BigTable as a service to store state - hence state is remote. I would simply write here "Such operators typically maintain state and exchange ...". Local state is already a design choice of Flink. (2) I would personally completely drop the term "user defined function" or making any form of distinction between operators and user-functions - that is more confusing then helpful to the reader. Everything is operators. Whether they execute built-in functions, user-defined functions, or code generated from higher declarative abstractions really does not matter.}

%\stephan{This sections again is written under the specific assumption of local partitioned state, and it implicitly assumes that this is the common default model. I would assume that actually the opposite is true - most people come from a mental model of state and computation being separate: A computing system (stream processor) and a state system (database), where the computing system operates against the storage system. That is what most companies have implemented in their Infrastructure. The challenges you highlight are actually somewhat trivial in that model - re-scaling (at least of the computation) and applying patches happens on stateless containers, which makes it very simple.}

%- Why is it interesting and important?
%- Why is it hard? (E.g., why do naive approaches fail?)


%Why hasn't it been solved before? (Or, what's wrong with previous proposed  solutions? How does mine differ?)
%What are the key components of the approach and results? Also include any specific limitations.

In this work, we present a complete, continuous state management solution that builds on distributed snapshots. Flink's core state snapshotting mechanism enables consistent stateful processing in Apache Flink since version 0.9 (June 2015) and has been therefore hardened throughout frequent releases of the framework. Most especially, it has been extensively tested in production at some of the largest stream processing deployments yet, on 1000s of nodes  managing hundreds of gigabytes of state (see \autoref{sec:evaluation}). 
%\stephan{I would drop the 'Alibaba' in the text, just reference the cluster. A foot note may be okay instead.}
The state snapshotting mechanism is coordinated and pipelined, similarly to the classical Chandy-Lamport's protocol \cite{chandy1985distributed}. However, it further exploits ordering guarantees and asynchrony in a fine-tailored manner to superimpose the acquisition of consistent snapshots without heavily impacting throughput. More importantly, snapshots are compacted, limited to minimal computational state with the exception of cyclic dataflow graphs where the partial inclusion of records in-transit is necessary. 
%In situations where relaxed processing guarantees are acceptable (i.e. at-least once processing guarantees) a totally asynchronous version of the protocol can be selected on-demand. 
Moreover, state and output that can be accessed from outside the system (e.g. queryable state, pipeline output) is provided under different isolation levels (read committed or uncommitted) in order to satisfy the required trade off between consistency and latency. 
This paper is the first principled description of the techniques that are implemented in Apache Flink for state management. The main goal of this work is to accurately describe these techniques and their significance\footnote{Most authors have been involved in the conception and implementation of these core techniques. Yet, the full credit for the evolution of Flink's ecosystem goes to the Apache Flink community, currently having more than 250 contributors.}. To summarize, we make the following contributions in this paper:

\begin{itemize}
	\item We tailor state snapshotting to the needs of typical distributed stream processing pipelines on common, weakly connected dataflow graphs.
	\item We provide a complete end-to-end design for continuous stateful processing, from the conceptual view of state in the programming model to its physical counterpart implemented in various backends.
	\item We encapsulate different processing guarantees and isolation levels for accessing partitioned operator state and output, using snapshots.
	\item We demonstrate how snapshots can be utilized for a large variety of operational needs beyond failure recovery such as software patches, testing, system upgrades and rescaling.
	\item We describe live, large-scale pipeline production deployments that operate 24/7 in production and rely heavily on stateful processing coupled with runtime metrics and performance insights.
\end{itemize}

The rest of the paper is organized as follows: \autoref{sec:preliminaries} gives an overview of the Apache Flink stack and the basic principles behind distributed snapshots and associated consistency guarantees. In \autoref{sec:core} we describe the core state management mechanisms of Flink, namely its stateful programming abstractions, the snapshotting protocol and its practical usages.\autoref{sec:implementation} summarizes further implementation concerns such as backend support, concurrent snapshots, the ability to query uncommitted state as well as end-to-end guarantees. Finally, \autoref{sec:evaluation} describes existing large-scale deployments and discusses metrics related to Flink's snapshots, followed by related work in \autoref{sec:related} and our conclusions coupled with future work and acknowledgements summarized in \autoref{sec:conclusion}. 
