%!TEX root = main.tex

\section{Introduction}
\label{sec:intro}

%- What is the problem?
State management unifies a set of a hard requirements when it comes to systems for continuous processing over potentially unbounded data sets. Data pipelines written and deployed on such systems run 24/7, processing distributed streams of records while updating user-defined state that often expands outside fixed local memory capacities. Pipelines are defined in a declarative programming model and compiled down to a distributed dataflow graph of operators. Such operators typically have local state accessed by user-defined functions and exchange data over the network.

Major challenges arise when there is need to scale in or out, deal with partial failures or to simply change application logic with software patches, in a transparent manner. First, state should be trivially re-partionable to allow for seamless allocation to parallel operator instances. Second, the system should be able to durably persist distributed state and rollback complete pipelines whenever necessary without imposing heavy impact on the execution throughput or latency. More importantly, upon any form of reconfiguration, a pipeline should restore its state correctly without consistency violations, respecting the observable behavior of previous executions. Finally, any form of state exposure or output committed to a database, distributed file system, or other systems should respect standard isolation level guarantees that have been traditionally supported by transactional databases such as ``read-committed'' or ``read-uncommitted'' application state. This allows for a complete and reliable integration of continuous pipelines with other data processing ecosystem tools and mechanisms.

%- Why is it interesting and important?
%- Why is it hard? (E.g., why do naive approaches fail?)

These are all significant needs, required today for critical continuous applications that cannot tolerate data or computational loss such as financial data processing, IoT systems, and user-facing live services. 
%(also known as \emph{at-least-once} and \emph{exactly-once} processing guarantees)
While several of these important state management issues have been previously researched and applied in production systems, most known approaches fall sort on doing so transparently. For example, micro-batching techniques for reliable continuous processing (e.g. Apache Spark \cite{zaharia2012discretized}) sacrifice programming model transparency by enforcing batch-centric application logic, despite incremental optimisations \cite{venkataramandrizzle} that deal solely with amortizing associated latency costs. Other proprietary continuous processing system solutions \cite{millwheel} on the other hand, rely on heavy transactional per-record processing that in fact push critical complexities outside the system which assume high performance key value stores and fine-tailored hardware and network infrastructure. 

%Why hasn't it been solved before? (Or, what's wrong with previous proposed  solutions? How does mine differ?)

The core of our approach in Apache Flink builds on \emph{distributed snapshots}, a  classical concept that is proliferating anew today. Distributed snapshots have been studied originally for obtaining distributed state consistently under the demand to validate execution properties off-line or simply allow for distributed rollback recovery of arbitrary distributed processes \cite{elnozahy2002survey}. Several distributed computing systems have used different variations of snapshotting mechanisms \cite{murray2013naiad,low2012distributed}, though adopting sub-optimal protocols that impose global synchrony and thus halt computational progress while also persisting more state than needed within snapshots (i.e. records within network buffers).

%What are the key components of the approach and results? Also include any specific limitations.

We present a complete, continuous state management solution that is currently implemented on Apache Flink, a widely adopted data stream processor. Our snapshotting mechanism is coordinated, similarly to the classical Chandy \& Lamport's protocol \cite{chandy1985distributed}. However, it further exploits ordering guarantees and asynchrony in a fine-tailored manner to superimpose the acquisition of consistent global state savepoints without heavily impacting throughput. More importantly, savepoints are lightweight, partially asynchronous and contain nothing more than compacted operator state with the exception of cyclic dataflow graphs where the partial inclusion of records in-transit is necessary. In situations where relaxed processing guarantees are acceptable (i.e. at-least once processing guarantees) a totally asynchronous version of the protocol can be selected on-demand. Moreover, state and output that can be accessed from outside the system (e.g. queryable state, pipeline output) is provided under user-defined isolation levels (read committed or uncommitted) in order to satisfy the required trade off between consistency and latency. To summarize, we make the following contributions in this paper: \TODOX{update this at the end}

\begin{itemize}
	\item We tailor asynchronous state snapshotting to the needs of typical distributed stream processing pipelines.
	\item We encapsulate different processing guarantees and isolation levels for accessing partitioned operator state and output, within the snapshotting protocol itself.
	\item We provide a complete end-to-end design for stateful processing from programming model to file persistence
	\item We describe live, large-scale pipeline production deployments that operate 24/7 in production and rely heavily on stateful processing coupled with runtime metrics and performance insights.
	\item We demonstrate usages and large-deployments of Flink having different workloads and pipeline types.
\end{itemize}

The rest of the paper is organized as follows: \autoref{sec:preliminaries} gives an overview of the Apache Flink stack and the basic principles behind distributed snapshots and associated consistency guarantees. In \autoref{sec:core} we describe the core state management mechanisms of Flink, namely the state representations, the snapshotting protocol as well as variations for cyclic graphs and associated practical usages. We summarize implementation concerns such as file management, concurrent snapshots, the ability to query uncommitted state as well as end-to-end guarantees coordinated between the existing snapshotting mechanism and file writes. Finally, \autoref{sec:evaluation} covers impact metrics under different pipeline types and consistency or isolation levels captured from existing large-scale deployments followed by related work in \autoref{sec:related}, acknowledgments in \autoref{sec:acknowledgements} and our conclusions coupled with future work summarized in \autoref{sec:conclusion}.
