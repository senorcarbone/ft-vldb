%!TEX root = main.tex

\section{Introduction}
\label{sec:intro}

Traditionally, when implementing data-driven applications and services, \emph{state} was separated from the application logic that performs the computation on data. The typical architecture has the state centralized in a database management system shared among applications that are either stateless or, rely on the database for data consistency and scalability among others.

Recently, stream processing has been gaining tremendous attention in the industry as a paradigm to implement both analytical applications on "real-time" data, but also as a paradigm to implement data-driven applications and services that would otherwise interact with an operational database for their data access needs. The stream processing paradigm is more friendly to modern organizations that separate engineering teams vertically, each team being responsible for a specific feature or application, as it allows state to be distributed and co-located with the application instead of forcing teams to collaborate by sharing access to an operational database. Further, stream processing is a natural paradigm for \emph{event-driven} applications that need to react fast to real-world events and communicate with each other via message passing. 

In point of fact, stream processing is not a new concept; it has been an active research topic for the database community in the past \cite{chen2000niagaracq,cherniack2003scalable,chandrasekaran2003telegraphcq,abadi2003aurora,arasu2004stream} and some (but not all) of the ideas that underpin modern stream processing technology are inspired by that research. However, what we see today is widespread adoption of stream processing across the enterprise beyond niche applications where stream processing and Complex Event Processing systems were traditionally used. There are many reasons for this: first, new stream processing technologies allow for massive scale-out similar to MapReduce \cite{dean2008mapreduce} and related technologies \cite{zaharia2010spark,stratosphere,battre2010nephele}. Second, the amount of data that is generated in the form of event streams is exploding. Processing needs now spread beyond financial transactions, to user activity in websites and mobile apps, as well as data generated by machines and sensors in manufacturing plants, cars, home devices, etc. Third, many modern state of the art stream processing systems are open source allowing widespread adoption in the developer community. Earlier attempts to distributed stream processing \cite{CUSTOM:web/Storm} provided distributed programming model semantics but focused on the challenge of providing real-time, perhaps approximate results that would later be augmented or corrected by more reliable, periodic (e.g., overnight) batch compute jobs (e.g., Lambda Architecture \cite{marz2015big}). While this addresses real-time compute on data records most challenges related to consistent state management remain a concern of the user and are typically lifted to external database management systems or traded off for further scalability.

%- What is the problem?
%Data stream processing has been traditionally decoupled from database management systems. When it comes to continuous data processing technologies, stream processors, have been viewed as a secondary tool for generating approximate, often inconsistent results in a timely manner. Recent advances in data streaming technologies have focused on providing distributed programming model semantics \cite{CUSTOM:web/Storm,CUSTOM:web/Samza} that can address large scale data ingestion, to deal with increasing data volumes. While this enables a new variety of applications, challenges related to consistent state management remain a concern of the user and are typically lifted to external database management systems or traded off for further scalability (e.g. Lambda Architecture \cite{marz2015big}).

We identified a set of hard challenges, faced daily by developers that architect critical continuous applications in the real world. First, the lack of explicit computational state abstractions in stream processing systems forces them to declare and maintain state externally, decoupled from computational logic. Hence, the burden of ensuring data consistency lies in the application logic, coordinating computation with external database systems. Often, this is complex to maintain as the code-base is divided across the state it manages. Second, transactions with external storage can become the bottleneck of the whole application. Finally, operational challenges arise when there is need to scale in or out, deal with partial failures or to simply change application logic with software patches. While several of these important state management issues have been previously researched and applied in production systems, most known approaches fall short of doing so in a transparent manner. For example, micro-batching techniques for reliable continuous processing (e.g. Apache Spark and Trident \cite{zaharia2012discretized,CUSTOM:web/trident}) sacrifice programming model transparency and processing latency by enforcing batch-centric application logic. Other proprietary continuous processing system solutions \cite{millwheel} on the other hand, build on heavy transactional per-record processing. This pushes critical complexities outside the system relying on high-performance key-value stores, special hardware and optimized network infrastructure. 

Apache Flink \cite{CUSTOM:web/Flink} is a stream processing system that addresses these challenges by closely integrating state management with computational logic. Flink's dataflow execution encapsulates distributed, record-centric operator logic to express complex data pipelines. Consistent application state is a first-class citizen in data processing pipelines written in Flink and is persisted using a modular state backend. Furthermore, the system manages operations on state and orchestrates failure recovery and reconfiguration (scale-out/in) whenever necessary without imposing heavy impact on the execution or violating consistency. Pipeline output committed to a database, distributed file system, or other systems respects standard isolation level guarantees that have been traditionally supported by transactional databases such as ``read-committed'' or ``read-uncommitted'' application state. The core of our approach in Apache Flink builds on \emph{distributed snapshots}, a  classical concept that is proliferating anew today. Distributed snapshots enable rollback recovery of arbitrary distributed processes \cite{elnozahy2002survey} to a prior globally consistent execution state. Several distributed computing systems have used different variations of snapshotting mechanisms \cite{murray2013naiad,low2012distributed}, though adopting sub-optimal protocols that impose global synchrony and thus halt computational progress while also persisting more state than required (i.e. records within network buffers).

%\stephan{Two comments on the last sentence: (1) State is not necessary "local", but may very well be remote. I think what you mean here is state that looks as if it is local and is used similar to operator-local state. Flink actually does not make the assumption that state is local (see Gyula's MySQL state backend) and the new DataFlow runner (as a service on Google Cloud) for Beam uses BigTable as a service to store state - hence state is remote. I would simply write here "Such operators typically maintain state and exchange ...". Local state is already a design choice of Flink. (2) I would personally completely drop the term "user defined function" or making any form of distinction between operators and user-functions - that is more confusing then helpful to the reader. Everything is operators. Whether they execute built-in functions, user-defined functions, or code generated from higher declarative abstractions really does not matter.}

%\stephan{This sections again is written under the specific assumption of local partitioned state, and it implicitly assumes that this is the common default model. I would assume that actually the opposite is true - most people come from a mental model of state and computation being separate: A computing system (stream processor) and a state system (database), where the computing system operates against the storage system. That is what most companies have implemented in their Infrastructure. The challenges you highlight are actually somewhat trivial in that model - re-scaling (at least of the computation) and applying patches happens on stateless containers, which makes it very simple.}

%- Why is it interesting and important?
%- Why is it hard? (E.g., why do naive approaches fail?)


%Why hasn't it been solved before? (Or, what's wrong with previous proposed  solutions? How does mine differ?)
%What are the key components of the approach and results? Also include any specific limitations.

In this work, we present a complete, continuous state management solution that builds on distributed snapshots. Flink's snapshotting mechanism has been in use since version 0.9 (June 2015) and therefore hardened throughout frequent releases of the framework and extensively tested in production at some of the largest stream processing deployments in the world, on 1000s of nodes  managing hundreds of gigabytes of state (see \autoref{sec:evaluation}). 
%\stephan{I would drop the 'Alibaba' in the text, just reference the cluster. A foot note may be okay instead.}
The state snapshotting mechanism is coordinated and pipelined, similarly to the classical Chandy-Lamport's protocol \cite{chandy1985distributed}. However, it is fine-tailored for weakly connected dataflow graphs to superimpose the acquisition of consistent snapshots without heavily impacting throughput. More importantly, snapshots are compacted, limited to minimal computational state with the exception of cyclic dataflow graphs where the partial inclusion of records in-transit is necessary. 
%In situations where relaxed processing guarantees are acceptable (i.e. at-least once processing guarantees) a totally asynchronous version of the protocol can be selected on-demand. 
Moreover, state and output that can be accessed from outside the system (e.g. queryable state, pipeline output) is provided under different isolation levels (read committed or uncommitted) in order to satisfy the required trade off between consistency and latency. 
This paper is the first principled description of the techniques that are implemented in Apache Flink for state management. The main goal of this work is to accurately describe these techniques and their significance\footnote{Most authors have been involved in the conception and implementation of these core techniques. Yet, the full credit for the evolution of Flink's ecosystem goes to the Apache Flink community, currently having more than 250 contributors.}. To summarize, this paper's contributions:

\begin{itemize}
	\item We tailor state snapshotting to the needs of typical distributed stream processing pipelines on common, weakly connected dataflow graphs.
	\item We provide a complete end-to-end design for continuous stateful processing, from the conceptual view of state in the programming model to its physical counterpart implemented in various backends.
	\item We encapsulate different processing guarantees and isolation levels for accessing partitioned operator state and output, using snapshots.
	\item We demonstrate how snapshots can be utilized for a large variety of operational needs beyond failure recovery such as software patches, testing, system upgrades and rescaling.
	\item We describe live, large-scale pipeline production deployments that operate 24/7 in production and rely heavily on stateful processing coupled with runtime metrics and performance insights.
\end{itemize}

The rest of the paper is organized as follows: \autoref{sec:preliminaries} gives an overview of the Apache Flink stack and the basic principles behind distributed snapshots and associated consistency guarantees. In \autoref{sec:core} we describe the core state management mechanisms of Flink, namely its stateful programming abstractions, the snapshotting protocol and its practical usages.\autoref{sec:implementation} summarizes further implementation concerns such as backend support, concurrent snapshots, the ability to query uncommitted state as well as end-to-end guarantees. Finally, \autoref{sec:evaluation} describes existing large-scale deployments and discusses metrics related to Flink's snapshots, followed by related work in \autoref{sec:related} and our conclusions coupled with future work and acknowledgements summarized in \autoref{sec:conclusion}. 
