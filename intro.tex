%!TEX root = main.tex

\section{Introduction}
\label{sec:intro}

%- What is the problem?
State management unifies a set of a hard requirements when it comes to systems for continuous processing over potentially unbounded data sets (e.g., Apache Beam \cite{CUSTOM:web/beam}, Flink \cite{carbone2015flink}, Spark Streaming \cite{zaharia2012discretized}, Storm \cite{CUSTOM:web/Storm}). Data pipelines written and deployed on such systems run 24/7, processing distributed streams of records while updating user-defined state that often expands outside fixed local memory capacities. In dataflow-based systems, pipelines are typically defined in a declarative programming model (e.g., Dataflow \cite{akidau2015dataflow}, FlumeJava \cite{chambers2010flumejava}, Naiad \cite{murray2013naiad}) and compiled down to a distributed dataflow graph of operators. Such operators typically have local state accessed by user-defined functions and exchange data over the network. 

Major challenges arise when there is need to scale in or out, deal with partial failures or to simply change application logic with software patches, in a transparent manner. First, state should be  re-partionable to allow for seamless allocation to parallel operator instances. Second, the system should be able to durably commit continuous operations on state and recover from failures or rescale whenever necessary without imposing heavy impact on the execution throughput or latency. More importantly, upon any form of reconfiguration, a pipeline should restore its state correctly without violating consistency, respecting the observable behavior of previous executions. Finally, any form of state exposure or output committed to a database, distributed file system, or other systems should respect standard isolation level guarantees that have been traditionally supported by transactional databases such as ``read-committed'' or ``read-uncommitted'' application state. This allows for a complete and reliable integration of continuous pipelines with other data processing ecosystem tools and mechanisms.

%- Why is it interesting and important?
%- Why is it hard? (E.g., why do naive approaches fail?)

These are all significant needs, required today for critical continuous applications that cannot tolerate data or computational loss such as financial data processing, IoT systems, and user-facing live services. 
%(also known as \emph{at-least-once} and \emph{exactly-once} processing guarantees)
While several of these important state management issues have been previously researched and applied in production systems, most known approaches fall short of doing so transparently. For example, micro-batching techniques for reliable continuous processing (e.g. Apache Spark \cite{zaharia2012discretized}) sacrifice programming model transparency by enforcing batch-centric application logic.
%despite incremental optimisations \cite{venkataramandrizzle} that deal solely with amortizing associated latency costs. 
Other proprietary continuous processing system solutions \cite{millwheel} on the other hand, build on heavy transactional per-record processing that in fact push critical complexities outside the system, relying on high performance key value stores, fine-tailored hardware and optimized network infrastructure, not accessible by everyone. 

%Why hasn't it been solved before? (Or, what's wrong with previous proposed  solutions? How does mine differ?)

The core of our approach in Apache Flink builds on \emph{distributed snapshots}, a  classical concept that is proliferating anew today. Distributed snapshots have been studied originally for obtaining distributed state consistently under the demand to validate execution properties off-line or simply allow for distributed rollback recovery of arbitrary distributed processes \cite{elnozahy2002survey}. Several distributed computing systems have used different variations of snapshotting mechanisms \cite{murray2013naiad,low2012distributed}, though adopting sub-optimal protocols that impose global synchrony and thus halt computational progress while also persisting more state than needed within snapshots (i.e. records within network buffers).

%What are the key components of the approach and results? Also include any specific limitations.

We present a complete, continuous state management solution that builds on distributed snapshots. Flink's core state snapshotting mechanism enable consistent stateful processing in Apache Flink since version 0.9 (June 2015) and have been therefore hardened throughout frequent releases of the framework. Most especially, it has been extensively tested in production at some of the largest stream processing deployments yet (e.g., Alibaba's 1000-node cluster) managing hundreds of gigabytes of state. The state snapshotting mechanism is coordinated and pipelined, similarly to the classical Chandy \& Lamport's protocol \cite{chandy1985distributed}. However, it further exploits ordering guarantees and asynchrony in a fine-tailored manner to superimpose the acquisition of consistent state savepoints without heavily impacting throughput. More importantly, savepoints are compacted, limited to minimal computational state with the exception of cyclic dataflow graphs where the partial inclusion of records in-transit is necessary. 
%In situations where relaxed processing guarantees are acceptable (i.e. at-least once processing guarantees) a totally asynchronous version of the protocol can be selected on-demand. 
Moreover, state and output that can be accessed from outside the system (e.g. queryable state, pipeline output) is provided under user-defined isolation levels (read committed or uncommitted) in order to satisfy the required trade off between consistency and latency. 
This paper is the first principled description of the techniques that are implemented in Apache Flink for state management. The main goal of this work is to accurately describe these techniques and their significance\footnote{Most authors have been involved in the conception and implementation of these core techniques. Yet, the full credit for the evolution of Flink's ecosystem goes to the Apache Flink community, currently having more than 250 contributors.}. To summarize, we make the following contributions in this paper:

\begin{itemize}
	\item We tailor asynchronous state snapshotting to the needs of typical distributed stream processing pipelines on common, weakly connected dataflow graphs.
	\item We provide a complete end-to-end design for continuous stateful processing, from the conceptual view of state in the programming model to its physical counterpart implemented in various backends.
	\item We encapsulate different processing guarantees and isolation levels for accessing partitioned operator state and output, using snapshots.
	\item We demonstrate how snapshots can be utilized for a large variety of operational needs beyond failure recovery such as software patches, testing, system upgrades and rescaling.
	\item We describe live, large-scale pipeline production deployments that operate 24/7 in production and rely heavily on stateful processing coupled with runtime metrics and performance insights.
\end{itemize}

The rest of the paper is organized as follows: \autoref{sec:preliminaries} gives an overview of the Apache Flink stack and the basic principles behind distributed snapshots and associated consistency guarantees. In \autoref{sec:core} we describe the core state management mechanisms of Flink, namely the state representations, the snapshotting protocol as well as variations for cyclic graphs and associated practical usages. In \autoref{sec:implementation} summarize implementation concerns such as file management, concurrent snapshots, the ability to query uncommitted state as well as end-to-end guarantees coordinated between the existing snapshotting mechanism and file writes. Finally, \autoref{sec:evaluation} describes existing large-scale deployments and discusses metrics related to Flink's snapshots, followed by related work in \autoref{sec:related} and our conclusions coupled with future work and acknowledgements summarized in \autoref{sec:conclusion}. \gyula{Let's make sure we update this part at the end}
