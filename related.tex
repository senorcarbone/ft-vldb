%!TEX root = main.tex

\section{Related Work}
\label{sec:related}
\para{Reliable Dataflow Processing}: Flink offers coarse grained, job-level snapshot maintenance which offers various operational benefits. Several proposed reconfiguration and state management schemes \cite{castro2013integrating} are restricted to fine-grained task management and reconfiguration, thus, lacking the benefits, applications and scale of global snapshots \autoref{sec:savepoints}.IBM Streams employs a pipelined checkpointing mechanism \cite{jacques2016consistent} that executes in-flight with data streams as with Flink's, tailored to weakly connected graphs with potential cycles. The most distinct difference to Flink's approach is that IBM Stream coordinates a two-phase protocol: 1) First, all records in transit are consumed in order to make sure that they are reflected in the global state while blocking all outputs. 2) All operators trigger their snapshot in topological order, using markers as in our technique and resume normal operation. Flink's protocol only drains records within cycles without affecting regular processing whatsoever. Furthermore, Flink's alignment is a local operation and does not halt global progress or hold up output in an execution graph making it more transparent and non-intrusive. Finally, IBM Streams supports language abstractions for selective fault tolerance. On Flink, the choice of snapshotting state is achieved by simply using managed state versus unregistered state, without requiring further user intervention. In the scope of a pipeline/component, snapshots can also be enabled or disabled through Flink's configuration. 

Apache Storm \cite{CUSTOM:web/Storm} initially offered only guaranteed record processing through a form of event sourcing using record dependency tracking. However, the most recent releases incorporated Flink's algorithm to its core \cite{CUSTOM:web/stormsux} in order to support exactly-once processing guarantees. Meteor Shower \cite{wang2012meteor} employs a similar alignment phase to Flink. However, it cannot incorporate cyclic dataflow graphs which is a common case for online machine learning \cite{de2015samoa} and other applications. Furthermore, source upstream backup introduces heavy ingestion latency costs and is not necessary when input streams are persisted within durable logs \cite{kreps2011kafka}. The same solution does not cover state rescaling and transparent programming model concerns. Naiad \cite{murray2013naiad} and the sweeping checkpointing technique [15] enforce in-transit state logging even in subgraphs where cycles are not present. Furthermore, Naiad's proposed three phase commit disrupts the overall execution for the purpose of snapshotting. Finally, MillWheel \cite{millwheel} offered a complete solution to end-to-end processing guarantees, similarly to Flink. However, its heavy transactional nature, idempotency constraints and strong dependence on a high-throughput, always-available, replicated data store \cite{chang2008bigtable,corbett2013spanner} makes this approach unfeasible in commodity deployments. In fact, Apache Flink serves today as a feature-complete runner of Apache Beam, Google's open-source implementation of the Dataflow Model\cite{CUSTOM:web/Dataflow}.

\para{Microbatching}: Stream micro-batching or batch-stream processing (e.g. Spark Streaming \cite{zaharia2012discretized}, Comet \cite{he2010comet}) emulates continuous, consistent data processing through recurring deterministic batch processing operations. In essence, this approach assigns distinct epochs of a stream to be scheduled independently. Fault tolerance and reconfiguration is guaranteed out-of-the-box through reliable batch processing at the cost of high reconfiguration latency and restrictive, programming model limited to incremental, deterministic set operations. Trident \cite{CUSTOM:web/trident}, a higher level framework built on Apache Storm offered exactly-once processing guarantees through a similar transactional approach on predefined sets but executed on long-running data stream tasks. While fault tolerance is guaranteed with such techniques, we argue that high latency and such programming model restrictions make this approach non-transparent to the user and often fall short in expressivity for real-world use-cases.
